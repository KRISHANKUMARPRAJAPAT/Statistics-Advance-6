{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37b729e-c671-446f-ad3a-8cbe77ef3024",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0474ac9b-3678-45a3-a20d-775f00904ec7",
   "metadata": {},
   "source": [
    "# Ans: 1 \n",
    "\n",
    "\n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means of three or more groups or conditions. It allows us to determine if there are significant differences among the means of these groups. However, ANOVA comes with certain assumptions that must be met to ensure the validity and reliability of the results. Violating these assumptions can impact the accuracy of the ANOVA analysis. \n",
    "\n",
    "\n",
    "**The main assumptions for ANOVA are as follows:**\n",
    "\n",
    "- **Normality of Residuals:** The residuals (the differences between the observed data and the group means) should follow a normal distribution. This assumption is essential, especially when the sample sizes are small. Violation of this assumption can lead to incorrect p-values and confidence intervals.\n",
    "\n",
    "- **Homogeneity of Variance:** The variances of the groups should be equal. In other words, the spread or dispersion of data points within each group should be similar. Violation of this assumption can lead to inflated or deflated Type I error rates and can affect the statistical power of the ANOVA test.\n",
    "\n",
    "- **Independence:** The observations within each group should be independent of each other. This means that the data points in one group should not be related or influenced by the data points in another group. Violation of independence can lead to biased estimates of the group means and inflated Type I error rates.\n",
    "\n",
    "**Examples of violations that could impact the validity of ANOVA results:**\n",
    "\n",
    "**Non-Normality:** If the residuals are not normally distributed, ANOVA results may not be reliable. For example, if the residuals follow a skewed distribution or have extreme outliers, the ANOVA test may produce inaccurate results.\n",
    "\n",
    "**Heteroscedasticity:** Heteroscedasticity occurs when the variances of the groups are not equal. This can lead to unequal influence of different groups on the overall test result. For instance, if one group has much higher variability than others, it may disproportionately affect the overall ANOVA outcome.\n",
    "\n",
    "**Lack of Independence:** If the data points within groups are not independent, ANOVA may produce biased estimates of the group means. For example, if repeated measures are used, and data points within each subject are correlated, it violates the independence assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59206560-dedf-4550-808b-e02b26ba94af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cab8704c-dba0-4f13-b4cd-455a082573bb",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf98abb-d4d1-4f23-a0ea-4b59cb9993c8",
   "metadata": {},
   "source": [
    "# Ans: 2 \n",
    "\n",
    "\n",
    "The three types of ANOVA (Analysis of Variance) are:\n",
    "\n",
    "- **One-Way ANOVA:** One-Way ANOVA is used when we want to compare the means of three or more groups that are organized into a single categorical independent variable. It is the most basic and commonly used form of ANOVA. For example, if we want to compare the average test scores of students from three different schools, where the schools are the categorical variable with three levels, we would use One-Way ANOVA.\n",
    "\n",
    "- **Two-Way ANOVA:** Two-Way ANOVA is used when we want to investigate the effects of two independent categorical variables (factors) on a single continuous dependent variable. It allows us to examine both the main effects of each factor and their interaction effect on the dependent variable. For example, in a study examining the effects of both gender and treatment type on patient outcomes, where gender and treatment are two categorical factors, we would use Two-Way ANOVA.\n",
    "\n",
    "- **Repeated Measures ANOVA:** Repeated Measures ANOVA is used when we have a single group of participants and measure the same dependent variable multiple times under different conditions or at different time points. This type of ANOVA is also known as within-subjects ANOVA. It is used to assess whether there are significant differences in the dependent variable across the different conditions or time points. For example, if we measure the reaction times of participants under three different conditions (e.g., before, during, and after a task), we would use Repeated Measures ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29975ffa-81a8-4edf-9edf-cea7b689d799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbc4b1fd-288f-4481-9503-add0997a4f43",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff96bed-683b-405c-9b38-9db78e82749f",
   "metadata": {},
   "source": [
    "# Ans: 3 \n",
    "\n",
    "The partitioning of variance in ANOVA is the process of breaking down the total variation in data into two parts:\n",
    "\n",
    "**Between-Group Variance:** It shows how much the group means differ from each other. If it's large, it means the groups are significantly different.\n",
    "\n",
    "**Within-Group Variance:** It shows how much individual data points vary within each group. It represents random variation within groups.\n",
    "\n",
    "Understanding this concept helps us know if the independent variable has a significant effect on the dependent variable and if the model fits the data well. It also helps identify sources of variability in the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bee383-463b-45e0-8dea-55b746da9712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "298b938a-93da-49f4-ae1a-68cc1299910e",
   "metadata": {},
   "source": [
    "# Q.4 How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb9791-8084-4994-86a1-72243004be68",
   "metadata": {},
   "source": [
    "# Ans: 4 \n",
    "\n",
    "In a one-way ANOVA, we can calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) to understand the variability in the data and assess the goodness of fit of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587bc766-ae7b-4769-ac37-66cdcb865ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 229.6\n",
      "Explained Sum of Squares (SSE): 194.79999999999998\n",
      "Residual Sum of Squares (SSR): 34.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data for three groups (replace this with your actual data)\n",
    "group1 = [5, 8, 7, 6, 10]\n",
    "group2 = [12, 9, 11, 13, 10]\n",
    "group3 = [15, 18, 14, 17, 16]\n",
    "\n",
    "# Combine all the data into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean of the data\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the Total Sum of Squares\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate the group means\n",
    "group1_mean = np.mean(group1)\n",
    "group2_mean = np.mean(group2)\n",
    "group3_mean = np.mean(group3)\n",
    "\n",
    "# Calculate the Explained Sum of Squares \n",
    "sse = len(group1) * (group1_mean - overall_mean)**2 + len(group2) * (group2_mean - overall_mean)**2 + len(group3) * (group3_mean - overall_mean)**2\n",
    "\n",
    "# Calculate the Residual Sum of Squares \n",
    "ssr = np.sum((group1 - group1_mean)**2) + np.sum((group2 - group2_mean)**2) + np.sum((group3 - group3_mean)**2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d83a65-4b92-44c1-bc6f-03462126a618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce9ddd39-1b8c-42e4-993c-f4af6d4fcc81",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf67bed-f9c7-4428-92cb-6576ce45f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  df        sum_sq       mean_sq             F    PR(>F)\n",
      "Factor2          1.0  1.500000e+00  1.500000e+00  1.058824e-01  0.775769\n",
      "Factor1          1.0  1.000000e+00  1.000000e+00  7.058824e-02  0.815363\n",
      "Factor1:Factor2  1.0  3.155444e-30  3.155444e-30  2.227372e-31  1.000000\n",
      "Residual         2.0  2.833333e+01  1.416667e+01           NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Ans: 5\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "data = {\n",
    "    'Factor1': [1, 2, 3, 4, 5, 6],\n",
    "    'Factor2': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'DependentVariable': [10, 12, 15, 8, 9, 11]\n",
    "}\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('DependentVariable ~ Factor1 + Factor2 + Factor1:Factor2', data=df).fit()\n",
    "\n",
    "# Get the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c14a2a6-2b49-4618-849f-8a762ef648ac",
   "metadata": {},
   "source": [
    "**The ANOVA table will provide you with the following information:**\n",
    "\n",
    "- Main Effect of Factor1: This represents the significance of the effect of Factor1 on the dependent variable, considering the other variables in the model.\n",
    "\n",
    "- Main Effect of Factor2: This represents the significance of the effect of Factor2 on the dependent variable, considering the other variables in the model.\n",
    "\n",
    "- Interaction Effect (Factor1:Factor2): This represents the significance of the interaction between Factor1 and Factor2 on the dependent variable. It shows whether the combined effect of both factors is significantly different from the sum of their individual effects.\n",
    "\n",
    "By analyzing the ANOVA table, you can determine the main effects of each factor and their interaction effect, and understand how they contribute to the variability in the dependent variable in the two-way ANOVA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0d35d-3c17-4d73-9d21-39feddf717fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3ccc8ac-3fa2-4894-aebd-427ecd87f3ef",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce56877-7f93-42ac-afd8-e8dec2403a3b",
   "metadata": {},
   "source": [
    "# Ans : 6 \n",
    "\n",
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences among the means of three or more groups. The p-value associated with the F-statistic indicates the probability of observing the results (or more extreme results) under the assumption that the null hypothesis is true.\n",
    "\n",
    "In our case, you obtained an F-statistic of 5.23 and a p-value of 0.02. \n",
    "\n",
    "**Here's how we can interpret these results:**\n",
    "\n",
    "- **F-Statistic:** The F-statistic of 5.23 represents the ratio of variability between the group means to variability within the groups. A larger F-statistic indicates that the variability between group means is relatively large compared to the variability within each group.\n",
    "\n",
    "- **P-Value:** The p-value of 0.02 indicates the probability of observing the obtained F-statistic (or more extreme values) if the null hypothesis is true. In other words, it represents the evidence against the null hypothesis. A p-value of 0.02 suggests that there is a 2% chance of observing such a large F-statistic by random chance alone, assuming that there are no true differences between the group means (i.e., the null hypothesis is true).\n",
    "\n",
    ".\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "Since the p-value (0.02) is less than the significance level (often set at 0.05), we reject the null hypothesis. This means that there are significant differences among the means of the groups. In other words, the independent variable (the factor defining the groups) has a statistically significant effect on the dependent variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d7925-4274-45cf-9464-ed970d892137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab3b1842-e029-42fd-8595-afa5b5304c98",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed695e-0f6f-41cb-a808-21081b1e6571",
   "metadata": {},
   "source": [
    "# Ans: 7 \n",
    "\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA is important because the presence of missing values can affect the validity and reliability of the analysis. There are several methods to handle missing data, each with its own implications and potential consequences. Some common approaches include:\n",
    "\n",
    "- **Complete Case Analysis (Listwise Deletion):** This method involves excluding any participant with missing data from the analysis. It is the simplest approach, but it may lead to a loss of valuable information, reduced statistical power, and potential bias if the missingness is related to the outcome variable or other factors.\n",
    "\n",
    "- **Mean Imputation:** This method replaces missing values with the mean of the observed values for that variable. While this can preserve the sample size, it can lead to biased estimates, underestimation of standard errors, and an artificial increase in the apparent within-subject variability.\n",
    "\n",
    "- **Last Observation Carried Forward (LOCF):** This method carries the last observed value forward for missing data points. LOCF can introduce bias if there is a trend or systematic change in the data over time.\n",
    "\n",
    "- **Multiple Imputation:** Multiple imputation creates multiple plausible imputed datasets based on the observed data. It estimates the missing values multiple times, incorporating uncertainty due to missing data. This method provides more accurate estimates and standard errors, but it requires more complex analysis.\n",
    "\n",
    "- **Model-Based Imputation:** This approach uses statistical models to predict missing values based on observed data. Model-based imputation can be more accurate than simple mean imputation but may still introduce bias if the model is misspecified.\n",
    "\n",
    ".\n",
    "\n",
    "**The potential consequences of using different methods to handle missing data in a repeated measures ANOVA include:**\n",
    "\n",
    "- **Biased Estimates:** Some methods, like mean imputation and LOCF, can introduce bias in the estimated group means and treatment effects if the missing data mechanism is not missing completely at random (MCAR).\n",
    "\n",
    "- **Loss of Power:** Complete case analysis can result in reduced statistical power due to the loss of participants with missing data, especially if the missingness is related to the outcome variable.\n",
    "\n",
    "- **Inflated Type I Error:** Ignoring missing data or using inappropriate imputation methods can lead to inflated Type I error rates, resulting in false-positive findings.\n",
    "\n",
    "- **Underestimation of Variability:** Improper handling of missing data can underestimate within-subject variability, leading to wider confidence intervals and potentially failing to detect true treatment effects.\n",
    "\n",
    "- **Decreased Precision:** Inaccurate or inefficient handling of missing data can reduce the precision of parameter estimates and make the results less reliable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e73c2-4a71-46e5-8ef0-87924adbddda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "209a603a-92e7-4b83-9091-ac7eeebfee8f",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f2ccb-865e-44b1-bc7c-f90d34ac2c39",
   "metadata": {},
   "source": [
    "# Ans: 8 \n",
    "\n",
    "\n",
    "After conducting an analysis of variance (ANOVA) and obtaining a significant result indicating that there are differences among the group means, post-hoc tests are often used to identify which specific groups differ from each other. Post-hoc tests help to perform multiple pairwise comparisons and control the family-wise error rate, which is the probability of making at least one Type I error (false positive) among all the comparisons.\n",
    "\n",
    "**Some common post-hoc tests used after ANOVA include:**\n",
    "\n",
    "- **Tukey's Honestly Significant Difference (HSD):** Tukey's HSD test is one of the most widely used post-hoc tests. It compares all possible pairs of group means and determines whether their differences are significant. It is appropriate when the sample sizes are equal across groups and when you want to control the overall Type I error rate. This test tends to be more conservative than some other post-hoc tests.\n",
    "\n",
    "- **Bonferroni correction:** Bonferroni correction is a simple method to control the family-wise error rate. It divides the desired significance level (usually α = 0.05) by the number of comparisons being made. Each individual comparison's p-value must then be less than or equal to the adjusted significance level for significance. This correction is often used when you have a small number of planned comparisons.\n",
    "\n",
    "- **Scheffe's method** Scheffe's test is a conservative post-hoc test that is used when sample sizes are unequal and variances are not necessarily equal. It controls the family-wise error rate for all possible linear combinations of group means.\n",
    "\n",
    "- **Fisher's Least Significant Difference (LSD):** Fisher's LSD test is relatively less conservative than Tukey's HSD, making it useful when sample sizes are equal, and variances are equal or approximately equal. It is a good choice when there is a specific hypothesis about which groups to compare.\n",
    "\n",
    ".\n",
    "\n",
    "**Example situation:**\n",
    "\n",
    "Let's say a pharmaceutical company is testing the effectiveness of four different drugs (A, B, C, and D) in reducing blood pressure. They randomly assign 100 hypertensive patients into four groups, each receiving one of the four drugs. After the treatment period, they measure the average reduction in blood pressure for each group and run an ANOVA to determine if there are any significant differences among the drugs.\n",
    "\n",
    "The ANOVA results show a significant difference among the group means (p < 0.05). To identify which specific drug(s) are significantly different from others, they decide to use a post-hoc test. Since they have equal sample sizes and want to control the overall Type I error rate, they opt for Tukey's HSD test.\n",
    "\n",
    "The Tukey's HSD test reveals that drug A and drug B show no significant difference in their effects on blood pressure. However, both drug A and drug B produce significantly different results compared to drug C and drug D. Drug C and drug D also show no significant difference between them.\n",
    "\n",
    "With this analysis, the pharmaceutical company can now confidently identify which drugs have a meaningful impact on reducing blood pressure and make informed decisions regarding further development and marketing strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991dfca-580f-4e34-b78b-49fd97576fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66870bcc-6463-4248-ad6d-39293aa1da83",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3203e7-74bf-4915-8ff1-a74d557c8e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 755.8582766092261\n",
      "p-value: 4.334728192105363e-76\n"
     ]
    }
   ],
   "source": [
    "# Ans: 9 \n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Weight loss data for diets A, B, and C\n",
    "diet_A = [2.5, 3.1, 4.0, 3.8, 3.2, 2.9, 2.7, 3.5, 2.8, 3.3,\n",
    "          3.1, 2.6, 3.0, 3.6, 3.9, 2.8, 3.5, 2.9, 3.2, 3.3,\n",
    "          3.1, 2.7, 2.9, 2.5, 3.4, 3.2, 2.6, 3.3, 2.8, 2.7,\n",
    "          2.9, 3.1, 3.0, 3.5, 2.8, 3.2, 2.6, 2.7, 2.9, 3.4,\n",
    "          3.6, 3.3, 3.0, 2.8, 3.2, 2.9, 2.7, 2.5, 2.6]\n",
    "\n",
    "diet_B = [3.8, 3.5, 4.2, 4.0, 4.1, 3.9, 4.3, 3.6, 4.0, 4.1,\n",
    "          3.7, 3.9, 3.8, 4.2, 3.6, 3.9, 4.0, 4.1, 4.3, 4.2,\n",
    "          3.7, 3.8, 4.2, 3.6, 3.9, 4.0, 4.1, 4.3, 4.2, 3.7,\n",
    "          3.8, 3.6, 3.9, 3.8, 4.2, 3.6, 4.0, 4.1, 3.7, 3.9,\n",
    "          3.8, 4.2, 3.6, 3.9, 4.0, 4.1, 4.3, 4.2]\n",
    "\n",
    "diet_C = [1.9, 1.8, 1.7, 1.5, 1.9, 2.0, 1.6, 1.7, 1.8, 2.1,\n",
    "          1.5, 1.6, 2.0, 1.7, 1.8, 1.9, 1.6, 1.5, 2.0, 1.7,\n",
    "          1.9, 1.8, 1.5, 1.7, 1.6, 1.9, 2.0, 1.8, 2.1, 1.5,\n",
    "          1.6, 1.7, 1.8, 1.9, 2.0, 1.7, 1.5, 2.0, 1.8, 1.6,\n",
    "          1.9, 1.8, 1.7, 1.5, 1.6, 1.7, 1.8]\n",
    "\n",
    "# Combine the data into a list of arrays\n",
    "all_data = [np.array(diet_A), np.array(diet_B), np.array(diet_C)]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(*all_data)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c67f3-6723-4b4c-bc1d-e7227798d3b7",
   "metadata": {},
   "source": [
    "**let's interpret the results:**\n",
    "\n",
    "The F-statistic is the test statistic of the ANOVA. It measures the variability between group means relative to the variability within groups. The larger the F-statistic, the more evidence there is for the existence of significant differences among the group means.\n",
    "\n",
    "The p-value represents the probability of observing such an extreme F-statistic under the assumption that there are no significant differences among the group means. In other words, it indicates the likelihood of obtaining the observed results due to random chance alone.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "If the p-value is less than the chosen significance level (e.g., 0.05), we reject the null hypothesis and conclude that there are significant differences among the mean weight loss of the three diets.\n",
    "If the p-value is greater than the significance level, we fail to reject the null hypothesis, and we cannot conclude that there are significant differences among the mean weight loss of the three diets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca717919-7c8a-48e3-a01c-8ebf3b0cd028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b5d90f8-bb81-4017-b61d-ed8ed4fd40ae",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3983ecc3-4420-4850-bcb4-ae85fb604e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic for Program: 9.752352236138195\n",
      "p-value for Program: 0.0007945115709784991\n",
      "F-statistic for Experience: 0.50474438153198\n",
      "p-value for Experience: 0.48427001563135097\n",
      "F-statistic for Interaction: 0.511794472420521\n",
      "p-value for Interaction: 0.6058145945473807\n"
     ]
    }
   ],
   "source": [
    "# Ana: 10 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    \"Time\": [12.3, 13.1, 11.5, 10.8, 13.5, 12.9, 9.7, 11.2, 10.4, 11.6,\n",
    "             14.2, 13.9, 15.1, 14.8, 15.9, 16.3, 17.0, 16.2, 13.8, 14.4,\n",
    "             11.9, 11.6, 10.5, 9.8, 10.1, 12.7, 12.4, 14.5, 13.7, 15.2],\n",
    "    \"Program\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\",\n",
    "                \"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"A\", \"A\", \"A\", \"A\",\n",
    "                \"B\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\"],\n",
    "    \"Experience\": [\"Novice\", \"Novice\", \"Experienced\", \"Experienced\", \"Novice\", \"Novice\",\n",
    "                   \"Experienced\", \"Experienced\", \"Novice\", \"Experienced\",\n",
    "                   \"Novice\", \"Novice\", \"Experienced\", \"Experienced\", \"Experienced\",\n",
    "                   \"Experienced\", \"Experienced\", \"Experienced\", \"Experienced\", \"Experienced\",\n",
    "                   \"Novice\", \"Novice\", \"Novice\", \"Experienced\", \"Experienced\", \"Experienced\",\n",
    "                   \"Novice\", \"Experienced\", \"Experienced\", \"Experienced\"]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ Program + Experience + Program:Experience', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract F-statistics and p-values\n",
    "F_program = anova_table['F']['Program']\n",
    "F_experience = anova_table['F']['Experience']\n",
    "F_interaction = anova_table['F']['Program:Experience']\n",
    "p_program = anova_table['PR(>F)']['Program']\n",
    "p_experience = anova_table['PR(>F)']['Experience']\n",
    "p_interaction = anova_table['PR(>F)']['Program:Experience']\n",
    "\n",
    "print(\"F-statistic for Program:\", F_program)\n",
    "print(\"p-value for Program:\", p_program)\n",
    "\n",
    "print(\"F-statistic for Experience:\", F_experience)\n",
    "print(\"p-value for Experience:\", p_experience)\n",
    "\n",
    "print(\"F-statistic for Interaction:\", F_interaction)\n",
    "print(\"p-value for Interaction:\", p_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796d087-b96d-4b55-bf07-a9347d8858f5",
   "metadata": {},
   "source": [
    "**let's interpret the results:**\n",
    "\n",
    "**Main Effect of Software Program:**\n",
    "\n",
    "- The F-statistic for the main effect of software program (F_program) tests whether there are significant differences in the average time it takes to complete the task across the three different software programs.\n",
    "\n",
    "- The p-value for the main effect of software program (p_program) represents the probability of observing such an extreme F-statistic under the assumption that there are no significant differences among the programs.\n",
    "\n",
    "- If p_program is less than the chosen significance level (e.g., 0.05), we reject the null hypothesis and conclude that there are significant differences in the average time across the software programs.\n",
    "\n",
    ".\n",
    "\n",
    "**Main Effect of Employee Experience:**\n",
    "\n",
    "- The F-statistic for the main effect of employee experience (F_experience) tests whether there are significant differences in the average time it takes to complete the task between novice and experienced employees.\n",
    "\n",
    "- The p-value for the main effect of employee experience (p_experience) represents the probability of observing such an extreme F-statistic under the assumption that there are no significant differences between novice and experienced employees.\n",
    "\n",
    "- If p_experience is less than the chosen significance level (e.g., 0.05), we reject the null hypothesis and conclude that there are significant differences in the average time between novice and experienced employees.\n",
    "\n",
    ".\n",
    "\n",
    "**Interaction Effect between Software Program and Employee Experience:**\n",
    "\n",
    "- The F-statistic for the interaction effect (F_interaction) tests whether there is a significant interaction between the software program used and the employee experience level. This means that the effect of one variable depends on the levels of the other variable.\n",
    "\n",
    "- The p-value for the interaction effect (p_interaction) represents the probability of observing such an extreme F-statistic under the assumption that there is no interaction between software program and employee experience.\n",
    "\n",
    "- If p_interaction is less than the chosen significance level (e.g., 0.05), we reject the null hypothesis and conclude that there is a significant interaction effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14387752-2a59-49ac-a862-1f4c24cf02db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d954d0cb-32c0-4c8a-8c66-b6954aeddf6a",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad9d53c-2d40-46e1-bcf7-eb7563fa121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -14.393098704677211\n",
      "p-value: 5.755655840190321e-17\n",
      "There is a significant difference in test scores between the control and experimental groups.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj lower   upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental     10.4   0.0 8.9372 11.8628   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ans: 11\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Test scores data for the control and experimental groups\n",
    "control_scores = [70, 72, 68, 65, 74, 71, 69, 75, 68, 73,\n",
    "                  72, 70, 75, 71, 69, 70, 71, 73, 68, 72]\n",
    "\n",
    "experimental_scores = [80, 82, 79, 85, 81, 83, 78, 82, 79, 84,\n",
    "                       82, 80, 83, 79, 80, 81, 84, 82, 79, 81]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "print(\"T-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the result is significant (p-value < 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the control and experimental groups.\")\n",
    "\n",
    "# If the results are significant, perform a post-hoc test (Tukey's HSD)\n",
    "if p_value < 0.05:\n",
    "    # Combine the data and create a group indicator variable (0 for control, 1 for experimental)\n",
    "    all_scores = np.array(control_scores + experimental_scores)\n",
    "    group_indicator = np.array([\"Control\"] * len(control_scores) + [\"Experimental\"] * len(experimental_scores))\n",
    "    \n",
    "    # Create a DataFrame to use for the post-hoc test\n",
    "    data = pd.DataFrame({\"Scores\": all_scores, \"Group\": group_indicator})\n",
    "    \n",
    "    # Perform the post-hoc test (Tukey's HSD)\n",
    "    posthoc = MultiComparison(data[\"Scores\"], data[\"Group\"])\n",
    "    result = posthoc.tukeyhsd()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfff6aa-9942-4ffd-aa86-df138a0a2a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7d5bc0-7a21-45b8-9a03-42082dd7713b",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cbdf1-e705-451f-bff4-2f701c96624e",
   "metadata": {},
   "source": [
    "# Ans: 12\n",
    "\n",
    "For the given scenario, we should use a one-way ANOVA for independent samples to compare the average daily sales of the three retail stores. If the results are significant, we can follow up with a post-hoc test (e.g., Tukey's HSD) to identify which store(s) have significantly different sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6118979-1aef-4055-b2a5-e6582de3f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.72352941176479\n",
      "p-value: 1.839617085900212e-18\n",
      "There is a significant difference in average daily sales between the three stores.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1  group2  meandiff p-adj    lower    upper   reject\n",
      "----------------------------------------------------------\n",
      "Store A Store B  206.6667    0.0   151.672 261.6613   True\n",
      "Store A Store C     -45.0 0.1307  -99.9946   9.9946  False\n",
      "Store B Store C -251.6667    0.0 -306.6613 -196.672   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Daily sales data for Store A, Store B, and Store C\n",
    "store_A_sales = [1000, 1200, 900, 1100, 950, 1050, 1150, 1000, 1050, 1100,\n",
    "                 900, 1150, 1200, 950, 1000, 1100, 1050, 950, 1150, 1000,\n",
    "                 1200, 900, 1100, 950, 1050, 1150, 1000, 1050, 1100, 900]\n",
    "\n",
    "store_B_sales = [1300, 1250, 1350, 1200, 1100, 1400, 1150, 1300, 1250, 1350,\n",
    "                 1200, 1100, 1400, 1150, 1300, 1250, 1350, 1200, 1100, 1400,\n",
    "                 1150, 1300, 1250, 1350, 1200, 1100, 1400, 1150, 1300, 1250]\n",
    "\n",
    "store_C_sales = [950, 1000, 900, 1050, 1100, 950, 1000, 900, 1050, 1100,\n",
    "                 950, 1000, 900, 1050, 1100, 950, 1000, 900, 1050, 1100,\n",
    "                 950, 1000, 900, 1050, 1100, 950, 1000, 900, 1050, 1100]\n",
    "\n",
    "# Combine the data into a list of arrays\n",
    "all_sales = [np.array(store_A_sales), np.array(store_B_sales), np.array(store_C_sales)]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(*all_sales)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the result is significant (p-value < 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in average daily sales between the three stores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in average daily sales between the three stores.\")\n",
    "\n",
    "# If the results are significant, perform a post-hoc test (e.g., Tukey's HSD)\n",
    "if p_value < 0.05:\n",
    "    # Combine the data and create a group indicator variable (0 for Store A, 1 for Store B, 2 for Store C)\n",
    "    all_data = np.concatenate(all_sales)\n",
    "    group_indicator = np.array([\"Store A\"] * len(store_A_sales) + [\"Store B\"] * len(store_B_sales) +\n",
    "                               [\"Store C\"] * len(store_C_sales))\n",
    "    \n",
    "    # Create a DataFrame to use for the post-hoc test\n",
    "    data = pd.DataFrame({\"Sales\": all_data, \"Store\": group_indicator})\n",
    "    \n",
    "    # Perform the post-hoc test (e.g., Tukey's HSD)\n",
    "    posthoc = MultiComparison(data[\"Sales\"], data[\"Store\"])\n",
    "    result = posthoc.tukeyhsd()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8016f51-1553-47c2-8074-7b67bc3226ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f10cec-6b74-4968-9b02-02592d6f279a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572d390-041d-45f8-b4a1-e0e7e9e0de09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
